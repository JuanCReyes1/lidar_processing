{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import laspy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to load .las data into a laspy object.\n",
    "def load_laspy(las_location):\n",
    "      input_las = laspy.read(las_location)\n",
    "      \n",
    "      return input_las\n",
    "\n",
    "#used to return a list of unique classifications present in the input LAS file.\n",
    "def get_list_classifications(input_las):\n",
    "    classifications = list(set(input_las.classification))\n",
    "    classifications.sort()\n",
    "    \n",
    "    return classifications\n",
    "\n",
    "#Used to return a Python dictionary of laspy objects of the entire dataset as well as individual classifications.\n",
    "def get_classifications_laspy(input_las):\n",
    "    #get a unique list of the classifications currently contained in the dataset.\n",
    "    classifications = get_list_classifications(input_las=input_las)\n",
    "    #create dictionary with complete data for each province\n",
    "    d = {\"original_dataset\": input_las}\n",
    "    print(\"The classifications contained in this .las dataset are: \")\n",
    "    print(classifications)\n",
    "    print(\"Creating a python dictionary containing the entire dataset and individual classifications as separate laspy objects.\")\n",
    "    for classification in classifications:\n",
    "        print(\"Saving classification number: \" +str(classification))\n",
    "    \n",
    "        header = laspy.LasHeader(point_format=input_las.header.point_format, version=input_las.header.version)\n",
    "        header.scales = np.array([0.001, 0.001, 0.001])\n",
    "\n",
    "        classified_points = laspy.LasData(header)\n",
    "\n",
    "        epsg=2960\n",
    "        crs = pyproj.CRS.from_epsg(epsg)  # example: WGS84\n",
    "        classified_points.header.add_crs(crs)\n",
    "\n",
    "        #classified_points = laspy.create(point_format=input_las.header.point_format, file_version=input_las.header.version)\n",
    "\n",
    "        classified_points.points = input_las.points[input_las.classification == classification]\n",
    "\n",
    "        classified_points.header.offsets = input_las.header.offsets\n",
    "\n",
    "        \n",
    "        d[\"classification_{}\".format(str(classification))] = classified_points\n",
    "    \n",
    "    return d\n",
    "\n",
    "#Optional function which takes the dictionary of laspy objects and converts every classification\n",
    "#   into individual .LAS files \n",
    "def laspy_classifications_to_las(classifications_laspy):\n",
    "    for classification_las in classifications_laspy:\n",
    "        if classification_las == \"original_dataset\":\n",
    "            pass\n",
    "            print(\"skipped exporting the original dataset.\")\n",
    "        else:\n",
    "            print(\"processing {} to a LAS file: \".format(classification_las))\n",
    "            print(classifications_laspy[classification_las])\n",
    "            classifications_laspy[classification_las].write(\"classification_{}.las\".format(classification_las.split(\"_\")[1]))\n",
    "            print(\"done\")\n",
    "\n",
    "# Convert a .LAS file into a pandas object.\n",
    "def convert_laspy_pandas(input_las):\n",
    "    # Convert data into pandas DataFrame\n",
    "    df = pd.DataFrame({\"X\":input_las.X,\"Y\":input_las.Y,\"Z\":input_las.Z,\n",
    "      \"x\":np.array(input_las.x),\"y\":np.array(input_las.y),\"z\":np.array(input_las.z),\n",
    "     'intensity': input_las.intensity,\n",
    "      'classification': input_las.classification,\n",
    "      'return_number': np.array(input_las.return_number),\n",
    "      'number_of_returns':np.array(input_las.number_of_returns),\n",
    "      'synthetic':np.array(input_las.synthetic),\n",
    "      'key_point':np.array(input_las.key_point),\n",
    "      'withheld':np.array(input_las.withheld),\n",
    "      'overlap':np.array(input_las.overlap),\n",
    "      'scanner_channel':np.array(input_las.scanner_channel),\n",
    "      'scan_direction_flag':np.array(input_las.scan_direction_flag),\n",
    "      'user_data':input_las.user_data,\n",
    "      'scan_angle':input_las.scan_angle,\n",
    "      'point_source_id':input_las.point_source_id,\n",
    "      'gps_time':input_las.gps_time    \n",
    "      })\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_selected_classes(classifications,input_las):\n",
    "    classes = get_list_classifications(input_las=input_las)\n",
    "    available_classes = classes\n",
    "    available_classes.append(1000) #to represent the entire dataset\n",
    "    class_selections = []\n",
    "    current_selection = -10\n",
    "\n",
    "    while current_selection == -10:\n",
    "        print(\"Available classifications: \" + str(available_classes))\n",
    "        try:\n",
    "            current_selection = input(\"Enter a number from the list of available classifications. To get the full dataset enter 1000 : \\n\")\n",
    "            if current_selection.isnumeric() == False:\n",
    "                print(\"Invalid Character Input.\")\n",
    "                raise ValueError()\n",
    "            current_selection = int(current_selection)\n",
    "            if current_selection not in available_classes:\n",
    "                print(\"The classification number you selected: {}, is not an available class item.\".format(current_selection))\n",
    "                cancel = input(\"Would you like to exit instead? 'Y/N' \").upper() + \"Y\"\n",
    "                if cancel[0] == \"Y\":\n",
    "                    current_selection = -1000\n",
    "                    print(\"Exiting and returning empty classification selection list.\")\n",
    "                    class_selections = []    \n",
    "                else: \n",
    "                    raise ValueError()\n",
    "            if (current_selection != -1000) & (current_selection != 1000):\n",
    "\n",
    "                if 1000 in available_classes:\n",
    "                    available_classes.remove(1000)\n",
    "                class_selections.append(current_selection)\n",
    "                print(\"Class {} added to dataframe.\".format(str(current_selection)))\n",
    "                available_classes.remove(current_selection)\n",
    "                ask = input(\"Would you like to add another classification to the dataframe? 'Y/N' \").upper() + \"Y\"\n",
    "\n",
    "                #If user prompts to add another classification, reset variable and start again.\n",
    "                if ask[0] == \"Y\":\n",
    "                    current_selection = -10\n",
    "                #If user prompts to stop, exit loop and create pandas dataframe.\n",
    "                else:\n",
    "                    print(\"Classifications have been selected.\")\n",
    "                    class_selections.sort()\n",
    "\n",
    "            elif current_selection == 1000:\n",
    "                print(\"The entire dataset has been selected\")\n",
    "                class_selections = get_list_classifications(input_las=input_las)\n",
    "                print(\"All classes have been added to the dataframe.\")\n",
    "                class_selections.sort()\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"Please select an input from the available classification list. \\n\")\n",
    "            current_selection = -10\n",
    "\n",
    "    \n",
    "    return class_selections\n",
    "\n",
    "def create_combined_classifications_dataframe(class_selections,df):\n",
    "    if len(class_selections) > 0:\n",
    "        #initialize the dataframe with the first set of classifications\n",
    "        combined_df = df.loc[df[\"classification\"] == class_selections[0]]\n",
    "        #iterate and append remaining classifications \n",
    "        for selection in class_selections[1:]:\n",
    "            combined_df=pd.concat([combined_df, df.loc[df[\"classification\"] == selection]])\n",
    "    else:\n",
    "        combined_df = pd.DataFrame()\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "def create_laspy_from_dataframe(input_las,combined_df):\n",
    "    classified_points = laspy.create(point_format=input_las.header.point_format, file_version=input_las.header.version)\n",
    "\n",
    "    classified_points.X = combined_df[\"X\"]\n",
    "    classified_points.Y = combined_df[\"Y\"]\n",
    "    classified_points.Z = combined_df[\"Z\"]\n",
    "    classified_points.intensity = combined_df[\"intensity\"]\n",
    "    classified_points.classification = combined_df[\"classification\"]\n",
    "\n",
    "    return classified_points\n",
    "\n",
    "def get_numpy_points_from_laspy_scaled(classified_points):\n",
    "    point_records = classified_points.points.copy()\n",
    "    # getting scaling and offset parameters\n",
    "    las_scaleX = classified_points.header.scale[0]\n",
    "    las_offsetX = classified_points.header.offset[0]\n",
    "    las_scaleY = classified_points.header.scale[1]\n",
    "    las_offsetY = classified_points.header.offset[1]\n",
    "    las_scaleZ = classified_points.header.scale[2]\n",
    "    las_offsetZ = classified_points.header.offset[2]\n",
    "    # calculating coordinates\n",
    "    p_X = np.array((point_records.X * las_scaleX) + las_offsetX) \n",
    "    p_Y = np.array((point_records.Y * las_scaleY) + las_offsetY)\n",
    "    p_Z = np.array((point_records.Z * las_scaleZ) + las_offsetZ)\n",
    "\n",
    "    classified_points_numpy = np.array(list(zip(p_X,p_Y,p_Z)))\n",
    "\n",
    "    return classified_points_numpy\n",
    "\n",
    "\n",
    "def get_numpy_points_from_laspy_unscaled(classified_points):\n",
    "    point_records = classified_points.points.copy()\n",
    "    # calculating coordinates\n",
    "    p_X = np.array(point_records.X)\n",
    "    p_Y = np.array(point_records.Y)\n",
    "    p_Z = np.array(point_records.Z)\n",
    "\n",
    "    classified_points_numpy = np.array(list(zip(p_X,p_Y,p_Z)))\n",
    "\n",
    "    return classified_points_numpy\n",
    "\n",
    "def get_numpy_points_from_pandas_unscaled(combined_df):\n",
    "\n",
    "    classified_points_numpy = np.array(list(zip(np.array(combined_df[\"X\"]),\n",
    "                                    np.array(combined_df[\"Y\"]),\n",
    "                                    np.array(combined_df[\"Z\"]))))\n",
    "\n",
    "    return classified_points_numpy\n",
    "\n",
    "def get_numpy_points_from_pandas_scaled(combined_df):\n",
    "\n",
    "    classified_points_numpy = np.array(list(zip(np.array(combined_df[\"x\"]),\n",
    "                                    np.array(combined_df[\"y\"]),\n",
    "                                    np.array(combined_df[\"z\"]))))\n",
    "\n",
    "    return classified_points_numpy\n",
    "\n",
    "#input numpy array to visualize using open3d\n",
    "def visualize_las(classified_points,df= pd.DataFrame()):\n",
    "        \n",
    "    dataset = classified_points\n",
    "    geom = o3d.geometry.PointCloud()\n",
    "    geom.points = o3d.utility.Vector3dVector(dataset)\n",
    "    #geom.colors = o3d.utility.Vector3dVector(x)\n",
    "    #print(df)\n",
    "\n",
    "    if df.empty is False:\n",
    "        print(\"entered df\")\n",
    "        #coord = o3d.geometry.TriangleMesh().create_coordinate_frame(size=df.X[0], origin=[df.X.mean(), df.Y.mean(), df.Z.mean()])\n",
    "        #coord = o3d.geometry.TriangleMesh().create_coordinate_frame(size=0.5, origin=[df.X.mean(),df.Y.mean(),df.Z.mean()])\n",
    "        coord = o3d.geometry.TriangleMesh().create_coordinate_frame(size=0.5, origin=[0,0,0])\n",
    "        o3d.visualization.draw_geometries([coord,geom])\n",
    "        #o3d.visualization.draw_geometries([geom])\n",
    "\n",
    "    else:\n",
    "        o3d.visualization.draw_geometries([geom])\n",
    "        print(\"did not enter df\")\n",
    "\n",
    "\n",
    "def create_laspy_from_dataframe(input_las,combined_df):\n",
    "    #classified_points = laspy.create(point_format=input_las.header.point_format, file_version=input_las.header.version)\n",
    "\n",
    "    #Create a header for the new .Las file\n",
    "    # Header class properties (https://laspy.readthedocs.io/en/latest/api/laspy.header.html)\n",
    "    header = laspy.LasHeader(point_format=input_las.header.point_format, version=input_las.header.version)\n",
    "    header.scales = np.array([0.001, 0.001, 0.001])\n",
    "\n",
    "    crs = pyproj.CRS.from_epsg(2960)  # example: WGS84\n",
    "    \n",
    "    classified_points = laspy.LasData(header)\n",
    "\n",
    "    classified_points.X = combined_df[\"X\"]\n",
    "    classified_points.Y = combined_df[\"Y\"]\n",
    "    classified_points.Z = combined_df[\"Z\"]\n",
    "    classified_points.intensity = combined_df[\"intensity\"]\n",
    "    classified_points.classification = combined_df[\"classification\"]\n",
    "\n",
    "\n",
    "    #Apply the add_crs function to add a crs to our header.\n",
    "    classified_points.header.add_crs(crs)\n",
    "    #Select the offset from the input las data.\n",
    "    classified_points.header.offsets = input_las.header.offsets\n",
    "    #header.y_offset=0\n",
    "\n",
    "    return classified_points\n",
    "    \n",
    "\n",
    "def multiple_classifications_to_las(classified_points,class_selections):\n",
    "    ##write to a .las file\n",
    "    class_selections.sort()\n",
    "    sorted_classes_str = \"_\".join(map(str,class_selections))\n",
    "    las_file_name = \"classifications_\" + sorted_classes_str +\".las\"\n",
    "    classified_points.write(las_file_name)\n",
    "    print(\"Created file: \" + sorted_classes_str)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifications contained in this .las dataset are: \n",
      "[0, 7, 9, 18, 40, 41, 42, 80]\n",
      "Creating a python dictionary containing the entire dataset and individual classifications as separate laspy objects.\n",
      "Saving classification number: 0\n",
      "Saving classification number: 7\n",
      "Saving classification number: 9\n",
      "Saving classification number: 18\n",
      "Saving classification number: 40\n",
      "Saving classification number: 41\n",
      "Saving classification number: 42\n",
      "Saving classification number: 80\n",
      "Available classifications: [0, 7, 9, 18, 40, 41, 42, 80, 1000]\n",
      "Class 40 added to dataframe.\n",
      "Available classifications: [0, 7, 9, 18, 41, 42, 80]\n",
      "Class 42 added to dataframe.\n",
      "Classifications have been selected.\n",
      "skipped exporting the original dataset.\n",
      "processing classification_0 to a LAS file: \n",
      "<LasData(1.4, point fmt: <PointFormat(6, 0 bytes of extra dims)>, 433239 points, 1 vlrs)>\n",
      "done\n",
      "processing classification_7 to a LAS file: \n",
      "<LasData(1.4, point fmt: <PointFormat(6, 0 bytes of extra dims)>, 23062 points, 1 vlrs)>\n",
      "done\n",
      "processing classification_9 to a LAS file: \n",
      "<LasData(1.4, point fmt: <PointFormat(6, 0 bytes of extra dims)>, 22378 points, 1 vlrs)>\n",
      "done\n",
      "processing classification_18 to a LAS file: \n",
      "<LasData(1.4, point fmt: <PointFormat(6, 0 bytes of extra dims)>, 2401 points, 1 vlrs)>\n",
      "done\n",
      "processing classification_40 to a LAS file: \n",
      "<LasData(1.4, point fmt: <PointFormat(6, 0 bytes of extra dims)>, 437724 points, 1 vlrs)>\n",
      "done\n",
      "processing classification_41 to a LAS file: \n",
      "<LasData(1.4, point fmt: <PointFormat(6, 0 bytes of extra dims)>, 73542 points, 1 vlrs)>\n",
      "done\n",
      "processing classification_42 to a LAS file: \n",
      "<LasData(1.4, point fmt: <PointFormat(6, 0 bytes of extra dims)>, 425932 points, 1 vlrs)>\n",
      "done\n",
      "processing classification_80 to a LAS file: \n",
      "<LasData(1.4, point fmt: <PointFormat(6, 0 bytes of extra dims)>, 57401 points, 1 vlrs)>\n",
      "done\n",
      "Created file: 40_42\n"
     ]
    }
   ],
   "source": [
    "input_las = load_laspy('Tile65_Original_Clean_Macro.las')\n",
    "\n",
    "\n",
    "\n",
    "#Obtain the classifications available for the dataset\n",
    "classifications = get_list_classifications(input_las=input_las)\n",
    "\n",
    "#Create a python dictionary containing the original dataset\n",
    "# as well as classifications in individual laspy objects.\n",
    "classifications_laspy =  get_classifications_laspy(input_las=input_las)\n",
    "\n",
    "\n",
    "df = convert_laspy_pandas(input_las=input_las)\n",
    "\n",
    "\n",
    "#To get a pandas dataframe with specified classification values\n",
    "#Inform user which class values are present \n",
    "#Proceed by prompting user input to select classes to group into a final dataframe.\n",
    "class_selections = get_selected_classes(classifications = classifications,input_las=input_las)\n",
    "\n",
    "# Form a pandas dataframe from user-selected classifications\n",
    "combined_df = create_combined_classifications_dataframe(class_selections=class_selections,df=df)\n",
    "\n",
    "##Create laspy points from the pandas dataframe of selected user classifications\n",
    "classified_points = create_laspy_from_dataframe(input_las=input_las,combined_df=combined_df)\n",
    "\n",
    "#create a las object for each classification set of points\n",
    "laspy_classifications_to_las(classifications_laspy=classifications_laspy)\n",
    "#export every single classification as its own .LAS data\n",
    "multiple_classifications_to_las(classified_points=classified_points,class_selections=class_selections)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifications contained in this .las dataset are: \n",
      "[0, 7, 9, 18, 40, 41, 42, 80]\n",
      "Creating a python dictionary containing the entire dataset and individual classifications as separate laspy objects.\n",
      "Saving classification number: 0\n",
      "Saving classification number: 7\n",
      "Saving classification number: 9\n",
      "Saving classification number: 18\n",
      "Saving classification number: 40\n",
      "Saving classification number: 41\n",
      "Saving classification number: 42\n",
      "Saving classification number: 80\n",
      "Available classifications: [0, 7, 9, 18, 40, 41, 42, 80, 1000]\n",
      "The entire dataset has been selected\n",
      "All classes have been added to the dataframe.\n"
     ]
    }
   ],
   "source": [
    "# Read .las file with the load_laspy() function. Note we cannot handle .laz data.\n",
    "input_las = load_laspy('Tile65_Original_Clean_Macro.las')\n",
    "#input_las = load_laspy(\"200-145324069_ground.las\")\n",
    "#Obtain the classifications available for the dataset\n",
    "classifications = get_list_classifications(input_las=input_las)\n",
    "#Create a python dictionary containing the original dataset\n",
    "# as well as classifications in individual laspy objects.\n",
    "classifications_laspy =  get_classifications_laspy(input_las=input_las)\n",
    "\n",
    "#If we choose to export each classification into individual .las files.\n",
    "#laspy_classifications_to_las(classifications_laspy=classifications_laspy)\n",
    "\n",
    "#Create a pandas dataframe containing the entire pointcloud.\n",
    "df = convert_laspy_pandas(input_las=input_las)\n",
    "#Create a pandas dataframe for ground class \"2\"\n",
    "if len(df[df[\"classification\"] == 2]) > 0:\n",
    "    ground = df[df[\"classification\"] == 2]\n",
    "#Create a pandas dataframe for low veg class \"3\"\n",
    "if len(df[df[\"classification\"] == 3]) > 0:\n",
    "    low_veg = df[df[\"classification\"] == 3]\n",
    "#Create a pandas dataframe for med veg class \"4\"\n",
    "if len(df[df[\"classification\"] == 4]) > 0:\n",
    "    med_veg = df[df[\"classification\"] == 4]\n",
    "#Create a pandas dataframe for high veg class \"5\"\n",
    "if len(df[df[\"classification\"] == 5]) > 0:\n",
    "    high_veg = df[df[\"classification\"] == 5]\n",
    "#Create a pandas dataframe for high veg class \"7\"\n",
    "if len(df[df[\"classification\"] == 7]) > 0:\n",
    "    low_noise = df[df[\"classification\"] == 7]\n",
    "#Create a pandas dataframe for high veg class \"9\"\n",
    "if len(df[df[\"classification\"] == 9]) > 0:\n",
    "    topo_water_surface = df[df[\"classification\"] == 9]\n",
    "#Create a pandas dataframe for high noise \"18\"\n",
    "if len(df[df[\"classification\"] == 18]) > 0:\n",
    "    high_noise = df[df[\"classification\"] == 18]\n",
    "#Create a pandas dataframe for classified bathymetry \"40\"\n",
    "if len(df[df[\"classification\"] == 40]) > 0:\n",
    "    bathymetry = df[df[\"classification\"] == 40]\n",
    "#Create a pandas dataframe for classified bathymetric water surface \"41\"\n",
    "if len(df[df[\"classification\"] == 41]) > 0:\n",
    "    bathymetric_water = df[df[\"classification\"] == 41]\n",
    "#Create a pandas dataframe for classified derived water surface \"42\"\n",
    "if len(df[df[\"classification\"] == 42]) > 0:\n",
    "    derived_water_surface = df[df[\"classification\"] == 42]\n",
    "#Create a pandas dataframe for bathymetric vegetation \"80\"\n",
    "if len(df[df[\"classification\"] == 80]) > 0:\n",
    "    bathy_veg = df[df[\"classification\"] == 80]\n",
    "#To get a pandas dataframe with specified classification values\n",
    "#Inform user which class values are present \n",
    "#Proceed by prompting user input to select classes to group into a final dataframe.\n",
    "class_selections = get_selected_classes(classifications = classifications,input_las=input_las)\n",
    "# Form a pandas dataframe from user-selected classifications\n",
    "combined_df = create_combined_classifications_dataframe(class_selections=class_selections,df=df)\n",
    "\n",
    "##Create laspy points from the pandas dataframe of selected user classifications\n",
    "classified_points = create_laspy_from_dataframe(input_las=input_las,combined_df=combined_df)\n",
    "\n",
    "###                                 ###\n",
    "###DATA CONVERSION FOR VISUALIZATION###\n",
    "###             #                   ###\n",
    "# Convert classified_points (laspy data) or combined_df (pandas data) to numpy data for visualization\n",
    "#   with the pptk library. \n",
    "#Convert from laspy to numpy scaled\n",
    "classified_points_numpy_scaled_laspy = get_numpy_points_from_laspy_scaled(classified_points=classified_points)\n",
    "#Convert from laspy to numpy unscaled\n",
    "classified_points_numpy_unscaled_laspy = get_numpy_points_from_laspy_unscaled(classified_points=classified_points)\n",
    "#Convert from pandas to numpy scaled\n",
    "classified_points_numpy_scaled_pandas = get_numpy_points_from_pandas_scaled(combined_df=combined_df)\n",
    "#Convert from pandas to numpy unscaled\n",
    "classified_points_numpy_unscaled_pandas = get_numpy_points_from_pandas_unscaled(combined_df=combined_df)\n",
    "\n",
    "\n",
    "\n",
    "########Individual Classifications#######\n",
    "low_noise_unscaled = get_numpy_points_from_pandas_unscaled(combined_df = low_noise)\n",
    "topo_water_surface_unscaled = get_numpy_points_from_pandas_unscaled(combined_df = topo_water_surface)\n",
    "high_noise_unscaled = get_numpy_points_from_pandas_unscaled(combined_df = high_noise)\n",
    "bathymetry_unscaled = get_numpy_points_from_pandas_unscaled(combined_df = bathymetry)\n",
    "bathymetric_water_unscaled = get_numpy_points_from_pandas_unscaled(combined_df = bathymetric_water)\n",
    "derived_water_surface_unscaled = get_numpy_points_from_pandas_unscaled(combined_df = derived_water_surface)\n",
    "bathy_veg_unscaled = get_numpy_points_from_pandas_unscaled(combined_df =bathy_veg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"X_mean_shift\"] = combined_df.X - combined_df.X.mean()\n",
    "combined_df[\"Y_mean_shift\"] = combined_df.Y - combined_df.Y.mean()\n",
    "combined_df[\"Z_mean_shift\"] = combined_df.Z - combined_df.Z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>intensity</th>\n",
       "      <th>classification</th>\n",
       "      <th>return_number</th>\n",
       "      <th>number_of_returns</th>\n",
       "      <th>synthetic</th>\n",
       "      <th>key_point</th>\n",
       "      <th>withheld</th>\n",
       "      <th>overlap</th>\n",
       "      <th>scanner_channel</th>\n",
       "      <th>scan_direction_flag</th>\n",
       "      <th>user_data</th>\n",
       "      <th>scan_angle</th>\n",
       "      <th>point_source_id</th>\n",
       "      <th>gps_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>290999485</td>\n",
       "      <td>-186802015</td>\n",
       "      <td>-6063</td>\n",
       "      <td>19192</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1890</td>\n",
       "      <td>2610</td>\n",
       "      <td>135243.728149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>290998268</td>\n",
       "      <td>-186801807</td>\n",
       "      <td>-6001</td>\n",
       "      <td>20705</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1864</td>\n",
       "      <td>2610</td>\n",
       "      <td>135243.728178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>290997022</td>\n",
       "      <td>-186801595</td>\n",
       "      <td>-5993</td>\n",
       "      <td>19004</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1836</td>\n",
       "      <td>2610</td>\n",
       "      <td>135243.728207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>290995781</td>\n",
       "      <td>-186801367</td>\n",
       "      <td>-5945</td>\n",
       "      <td>21545</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1809</td>\n",
       "      <td>2610</td>\n",
       "      <td>135243.728237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>290994546</td>\n",
       "      <td>-186801135</td>\n",
       "      <td>-5915</td>\n",
       "      <td>19130</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1781</td>\n",
       "      <td>2610</td>\n",
       "      <td>135243.728266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475458</th>\n",
       "      <td>291022825</td>\n",
       "      <td>-186959005</td>\n",
       "      <td>-251</td>\n",
       "      <td>65530</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2610</td>\n",
       "      <td>2812</td>\n",
       "      <td>135839.302463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475461</th>\n",
       "      <td>291024199</td>\n",
       "      <td>-186959004</td>\n",
       "      <td>-242</td>\n",
       "      <td>65530</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2585</td>\n",
       "      <td>2812</td>\n",
       "      <td>135839.302492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475465</th>\n",
       "      <td>291025607</td>\n",
       "      <td>-186959020</td>\n",
       "      <td>-226</td>\n",
       "      <td>65530</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2560</td>\n",
       "      <td>2812</td>\n",
       "      <td>135839.302521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475469</th>\n",
       "      <td>291027003</td>\n",
       "      <td>-186959050</td>\n",
       "      <td>-212</td>\n",
       "      <td>65530</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2534</td>\n",
       "      <td>2812</td>\n",
       "      <td>135839.302550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475472</th>\n",
       "      <td>291028384</td>\n",
       "      <td>-186959089</td>\n",
       "      <td>-214</td>\n",
       "      <td>65530</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2509</td>\n",
       "      <td>2812</td>\n",
       "      <td>135839.302579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937198 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 X          Y     Z  intensity  classification  return_number  \\\n",
       "2567     290999485 -186802015 -6063      19192              40              1   \n",
       "2568     290998268 -186801807 -6001      20705              40              1   \n",
       "2570     290997022 -186801595 -5993      19004              40              2   \n",
       "2572     290995781 -186801367 -5945      21545              40              2   \n",
       "2577     290994546 -186801135 -5915      19130              40              2   \n",
       "...            ...        ...   ...        ...             ...            ...   \n",
       "1475458  291022825 -186959005  -251      65530              42              0   \n",
       "1475461  291024199 -186959004  -242      65530              42              0   \n",
       "1475465  291025607 -186959020  -226      65530              42              0   \n",
       "1475469  291027003 -186959050  -212      65530              42              0   \n",
       "1475472  291028384 -186959089  -214      65530              42              0   \n",
       "\n",
       "         number_of_returns  synthetic  key_point  withheld  overlap  \\\n",
       "2567                     1          0          0         0        0   \n",
       "2568                     1          0          0         0        0   \n",
       "2570                     3          0          0         0        0   \n",
       "2572                     6          0          0         0        0   \n",
       "2577                     2          0          0         0        0   \n",
       "...                    ...        ...        ...       ...      ...   \n",
       "1475458                  2          0          0         0        0   \n",
       "1475461                  3          0          0         0        0   \n",
       "1475465                  3          0          0         0        0   \n",
       "1475469                  2          0          0         0        0   \n",
       "1475472                  5          0          0         0        0   \n",
       "\n",
       "         scanner_channel  scan_direction_flag  user_data  scan_angle  \\\n",
       "2567                   0                    1          2       -1890   \n",
       "2568                   0                    1          2       -1864   \n",
       "2570                   0                    1          2       -1836   \n",
       "2572                   0                    1          2       -1809   \n",
       "2577                   0                    1          2       -1781   \n",
       "...                  ...                  ...        ...         ...   \n",
       "1475458                0                    0          4        2610   \n",
       "1475461                0                    0          4        2585   \n",
       "1475465                0                    0          4        2560   \n",
       "1475469                0                    0          4        2534   \n",
       "1475472                0                    0          4        2509   \n",
       "\n",
       "         point_source_id       gps_time  \n",
       "2567                2610  135243.728149  \n",
       "2568                2610  135243.728178  \n",
       "2570                2610  135243.728207  \n",
       "2572                2610  135243.728237  \n",
       "2577                2610  135243.728266  \n",
       "...                  ...            ...  \n",
       "1475458             2812  135839.302463  \n",
       "1475461             2812  135839.302492  \n",
       "1475465             2812  135839.302521  \n",
       "1475469             2812  135839.302550  \n",
       "1475472             2812  135839.302579  \n",
       "\n",
       "[937198 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file: 40_41_42\n"
     ]
    }
   ],
   "source": [
    "multiple_classifications_to_las(classified_points=classified_points,class_selections=class_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38lidar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
