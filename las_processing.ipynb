{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laspy and pptk scripts for point cloud exploration point cloud visualization.\n",
    "\n",
    "#### Note that pptk needs python==3.6 and for this build, laspy has no .LAZ backend.\n",
    "\n",
    "##### Begin by importing necessary python libraries for using this notebook.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For importing .las data\n",
    "import laspy\n",
    "#For Data Cleaning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# For point cloud visualization\n",
    "import pptk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to load .las data into a laspy object.\n",
    "def load_laspy(las_location):\n",
    "      input_las = laspy.read(las_location)\n",
    "      \n",
    "      return input_las\n",
    "\n",
    "#used to return a list of unique classifications present in the input LAS file.\n",
    "def get_list_classifications(input_las):\n",
    "    classifications = list(set(input_las.classification))\n",
    "    \n",
    "    return classifications\n",
    "\n",
    "#Used to return a Python dictionary of laspy objects of the entire dataset as well as individual classifications.\n",
    "def get_classifications_laspy(input_las):\n",
    "    #get a unique list of the classifications currently contained in the dataset.\n",
    "    classifications = get_list_classifications(input_las=input_las)\n",
    "    #create dictionary with complete data for each province\n",
    "    d = {\"original_dataset\": input_las}\n",
    "    print(\"The classifications contained in this .las dataset are: \")\n",
    "    print(classifications)\n",
    "    print(\"Creating a python dictionary containing the entire dataset and individual classifications as separate laspy objects.\")\n",
    "    for classification in classifications:\n",
    "        print(\"Saving classification number: \" +str(classification))\n",
    "        classified_points = laspy.create(point_format=input_las.header.point_format, file_version=input_las.header.version)\n",
    "        classified_points.points = input_las.points[input_las.classification == classification]\n",
    "        \n",
    "        d[\"classification_{}\".format(str(classification))] = classified_points\n",
    "    \n",
    "    return d\n",
    "\n",
    "#Optional function which takes the dictionary of laspy objects and converts every classification\n",
    "#   into individual .LAS files \n",
    "def laspy_classifications_to_las(classifications_laspy):\n",
    "    for classification_las in classifications_laspy:\n",
    "        if classification_las == \"original_dataset\":\n",
    "            pass\n",
    "            print(\"skipped exporting the original dataset.\")\n",
    "        else:\n",
    "            print(\"processing {} to a LAS file: \".format(classification_las))\n",
    "            print(classifications_laspy[classification_las])\n",
    "            classifications_laspy[classification_las].write(\"classification_{}.las\".format(classification_las.split(\"_\")[1]))\n",
    "            print(\"done\")\n",
    "\n",
    "# Convert a .LAS file into a pandas object.\n",
    "def convert_laspy_pandas(input_las):\n",
    "    # Convert data into pandas DataFrame\n",
    "    df = pd.DataFrame({\"X\":input_las.X,\"Y\":input_las.Y,\"Z\":input_las.Z,\n",
    "      \"x\":np.array(input_las.x),\"y\":np.array(input_las.y),\"z\":np.array(input_las.z),\n",
    "     'intensity': input_las.intensity,\n",
    "      'classification': input_las.classification,\n",
    "      'return_number': np.array(input_las.return_number),\n",
    "      'number_of_returns':np.array(input_las.number_of_returns),\n",
    "      'synthetic':np.array(input_las.synthetic),\n",
    "      'key_point':np.array(input_las.key_point),\n",
    "      'withheld':np.array(input_las.withheld),\n",
    "      'overlap':np.array(input_las.overlap),\n",
    "      'scanner_channel':np.array(input_las.scanner_channel),\n",
    "      'scan_direction_flag':np.array(input_las.scan_direction_flag),\n",
    "      'user_data':input_las.user_data,\n",
    "      'scan_angle':input_las.scan_angle,\n",
    "      'point_source_id':input_las.point_source_id,\n",
    "      'gps_time':input_las.gps_time    \n",
    "      })\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_selected_classes(classifications,input_las):\n",
    "    classes = get_list_classifications(input_las=input_las)\n",
    "    available_classes = classes\n",
    "    class_selections = []\n",
    "    current_selection = -10\n",
    "    while current_selection == -10:\n",
    "        print(\"Available classifications: \" + str(available_classes))\n",
    "        try:\n",
    "            current_selection = input(\"Enter a number from the list of available classifications: \\n\")\n",
    "            if current_selection.isnumeric() == False:\n",
    "                print(\"Invalid Character Input.\")\n",
    "                raise ValueError()\n",
    "            current_selection = int(current_selection)\n",
    "\n",
    "            if current_selection not in available_classes:\n",
    "                print(\"The classification number you selected: {}, is not an available class item.\".format(current_selection))\n",
    "                \n",
    "                cancel = input(\"Would you like to exit instead? 'Y/N' \").upper() + \"Y\"\n",
    "\n",
    "                if cancel[0] == \"Y\":\n",
    "                    current_selection = 1000\n",
    "                    print(\"Exiting and returning empty classification selection list.\")\n",
    "                    class_selections = []\n",
    "                    \n",
    "                \n",
    "                else: \n",
    "                    raise ValueError()\n",
    "            \n",
    "            if current_selection != 1000:\n",
    "\n",
    "                class_selections.append(current_selection)\n",
    "                print(\"Class {} added to dataframe.\".format(str(current_selection)))\n",
    "                available_classes.remove(current_selection)\n",
    "                ask = input(\"Would you like to add another classification to the dataframe? 'Y/N' \").upper() + \"Y\"\n",
    "\n",
    "                #If user prompts to add another classification, reset variable and start again.\n",
    "                if ask[0] == \"Y\":\n",
    "                    current_selection = -10\n",
    "                #If user prompts to stop, exit loop and create pandas dataframe.\n",
    "                else:\n",
    "                    print(\"Classifications have been selected.\")\n",
    "                    class_selections.sort()\n",
    "                    \n",
    "\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"Please select an input from the available classification list. \\n\")\n",
    "            current_selection = -10\n",
    "\n",
    "    \n",
    "    return class_selections\n",
    "\n",
    "def create_combined_classifications_dataframe(class_selections,df):\n",
    "    if len(class_selections) > 0:\n",
    "        #initialize the dataframe with the first set of classifications\n",
    "        combined_df = df.loc[df[\"classification\"] == class_selections[0]]\n",
    "        #iterate and append remaining classifications \n",
    "        for selection in class_selections[1:]:\n",
    "            combined_df=pd.concat([combined_df, df.loc[df[\"classification\"] == selection]])\n",
    "    else:\n",
    "        combined_df = pd.DataFrame()\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "def create_laspy_from_dataframe(input_las,combined_df):\n",
    "    classified_points = laspy.create(point_format=input_las.header.point_format, file_version=input_las.header.version)\n",
    "    classified_points.X = combined_df[\"X\"]\n",
    "    classified_points.Y = combined_df[\"Y\"]\n",
    "    classified_points.Z = combined_df[\"Z\"]\n",
    "    classified_points.intensity = combined_df[\"intensity\"]\n",
    "    classified_points.classification = combined_df[\"classification\"]\n",
    "\n",
    "    return classified_points\n",
    "\n",
    "def get_numpy_points_from_laspy_scaled(classified_points):\n",
    "    point_records = classified_points.points.copy()\n",
    "    # getting scaling and offset parameters\n",
    "    las_scaleX = classified_points.header.scale[0]\n",
    "    las_offsetX = classified_points.header.offset[0]\n",
    "    las_scaleY = classified_points.header.scale[1]\n",
    "    las_offsetY = classified_points.header.offset[1]\n",
    "    las_scaleZ = classified_points.header.scale[2]\n",
    "    las_offsetZ = classified_points.header.offset[2]\n",
    "    # calculating coordinates\n",
    "    p_X = np.array((point_records.X * las_scaleX) + las_offsetX) \n",
    "    p_Y = np.array((point_records.Y * las_scaleY) + las_offsetY)\n",
    "    p_Z = np.array((point_records.Z * las_scaleZ) + las_offsetZ)\n",
    "\n",
    "    classified_points_numpy = np.array(list(zip(p_X,p_Y,p_Z)))\n",
    "\n",
    "    return classified_points_numpy\n",
    "\n",
    "\n",
    "def get_numpy_points_from_laspy_unscaled(classified_points):\n",
    "    point_records = classified_points.points.copy()\n",
    "    # calculating coordinates\n",
    "    p_X = np.array(point_records.X)\n",
    "    p_Y = np.array(point_records.Y)\n",
    "    p_Z = np.array(point_records.Z)\n",
    "\n",
    "    classified_points_numpy = np.array(list(zip(p_X,p_Y,p_Z)))\n",
    "\n",
    "    return classified_points_numpy\n",
    "\n",
    "def get_numpy_points_from_pandas_unscaled(combined_df):\n",
    "\n",
    "    classified_points_numpy = np.array(list(zip(np.array(combined_df[\"X\"]),\n",
    "                                    np.array(combined_df[\"Y\"]),\n",
    "                                    np.array(combined_df[\"Z\"]))))\n",
    "\n",
    "    return classified_points_numpy\n",
    "\n",
    "def get_numpy_points_from_pandas_scaled(combined_df):\n",
    "\n",
    "    classified_points_numpy = np.array(list(zip(np.array(combined_df[\"x\"]),\n",
    "                                    np.array(combined_df[\"y\"]),\n",
    "                                    np.array(combined_df[\"z\"]))))\n",
    "\n",
    "    return classified_points_numpy\n",
    "\n",
    "def pptk_view(numpy_points):\n",
    "    v = pptk.viewer(numpy_points)\n",
    "    v.set(point_size=0.1)\n",
    "\n",
    "def multiple_classifications_to_las(classified_points,class_selections):\n",
    "    ##write to a .las file\n",
    "    sorted_classes_str = \"_\".join(map(str,class_selections))\n",
    "    las_file_name = \"classifications_\" + sorted_classes_str +\".las\"\n",
    "    classified_points.write(las_file_name)\n",
    "    print(\"Created file: \" + sorted_classes_str)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Functions\n",
    "## This script is used for creating pandas dataframes for further analysis of LiDAR point clouds with other Python functions and libraries. \n",
    "## It is also used for visualizing the point clouds with the pptk visualization library.\n",
    "\n",
    "1 - Load data with load_laspy() and create a laspy object.\n",
    "\n",
    "2 - Get unique classifications from the laspy object using get_list_classifications().\n",
    "\n",
    "3 - Create a python dictionary which stores unique laspy objects for the entire las dataset, as well as individual classification coordinates.\n",
    "* - (Optional) - export all classifications as individual .LAS files)\n",
    "\n",
    "\n",
    "4 - Create pandas dataframe (df) for the entire dataset \n",
    "\n",
    "5 - Prompt user for which classifications they want to export to a dataframe, as well as visualize using the create_combined_classifications_dataframe() function.\n",
    "\n",
    "6 - Create a laspy object for all of the selected classifications.\n",
    "\n",
    "7 - Create a numpy array of coordinates (scaled and unscaled) for the chosen classifications.\n",
    "\n",
    "8 - Input numpy arrays into the pptk_view() function to visualize chosen classifications using pptk.\n",
    "\n",
    "\n",
    "* - (Optional) - Export chosen classifications to new .LAS file.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifications contained in this .las dataset are: \n",
      "[0, 7, 40, 9, 42, 41, 80, 18]\n",
      "Creating a python dictionary containing the entire dataset and individual classifications as separate laspy objects.\n",
      "Saving classification number: 0\n",
      "Saving classification number: 7\n",
      "Saving classification number: 40\n",
      "Saving classification number: 9\n",
      "Saving classification number: 42\n",
      "Saving classification number: 41\n",
      "Saving classification number: 80\n",
      "Saving classification number: 18\n",
      "Available classifications: [0, 7, 40, 9, 42, 41, 80, 18]\n",
      "Class 40 added to dataframe.\n",
      "Available classifications: [0, 7, 9, 42, 41, 80, 18]\n",
      "Class 42 added to dataframe.\n",
      "Classifications have been selected.\n"
     ]
    }
   ],
   "source": [
    "# Read .las file with the load_laspy() function. Note we cannot handle .laz data.\n",
    "input_las = load_laspy('Tile65_Original_Clean_Macro.las')\n",
    "#Obtain the classifications available for the dataset\n",
    "classifications = get_list_classifications(input_las=input_las)\n",
    "#Create a python dictionary containing the original dataset\n",
    "# as well as classifications in individual laspy objects.\n",
    "classifications_laspy =  get_classifications_laspy(input_las=input_las)\n",
    "\n",
    "#If we choose to export each classification into individual .las files.\n",
    "#laspy_classifications_to_las(classifications_laspy=classifications_laspy)\n",
    "\n",
    "#Create a pandas dataframe containing the entire pointcloud.\n",
    "df = convert_laspy_pandas(input_las=input_las)\n",
    "#Create a pandas dataframe for classified bathymetry \"40\"\n",
    "if len(df[df[\"classification\"] == 40]) > 0:\n",
    "    bathymetry = df[df[\"classification\"] == 40]\n",
    "#Create a pandas dataframe for classified water surface \"42\"\n",
    "if len(df[df[\"classification\"] == 42]) > 0:\n",
    "    ocean_surface = df[df[\"classification\"] == 42]\n",
    "\n",
    "#To get a pandas dataframe with specified classification values\n",
    "#Inform user which class values are present \n",
    "#Proceed by prompting user input to select classes to group into a final dataframe.\n",
    "class_selections = get_selected_classes(classifications = classifications,input_las=input_las)\n",
    "# Form a pandas dataframe from user-selected classifications\n",
    "combined_df = create_combined_classifications_dataframe(class_selections=class_selections,df=df)\n",
    "\n",
    "##Create laspy points from the pandas dataframe of selected user classifications\n",
    "classified_points = create_laspy_from_dataframe(input_las=input_las,combined_df=combined_df)\n",
    "\n",
    "###             ###\n",
    "###VISUALIZATION###\n",
    "###             ###\n",
    "# Convert classified_points (laspy data) or combined_df (pandas data) to numpy data for visualization\n",
    "#   with the pptk library. \n",
    "#Convert from laspy to numpy scaled\n",
    "classified_points_numpy_scaled_laspy = get_numpy_points_from_laspy_scaled(classified_points=classified_points)\n",
    "#Convert from laspy to numpy unscaled\n",
    "classified_points_numpy_unscaled_laspy = get_numpy_points_from_laspy_unscaled(classified_points=classified_points)\n",
    "#Convert from pandas to numpy scaled\n",
    "classified_points_numpy_scaled_pandas = get_numpy_points_from_pandas_scaled(combined_df=combined_df)\n",
    "#Convert from pandas to numpy unscaled\n",
    "classified_points_numpy_unscaled_pandas = get_numpy_points_from_pandas_unscaled(combined_df=combined_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View results usking PPTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes an array of numpy objects. \n",
    "pptk_view(numpy_points = classified_points_numpy_unscaled_laspy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to .las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_classifications_to_las(classified_points=classified_points,class_selections=class_selections)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13 |Anaconda, Inc.| (default, Feb 23 2021, 12:58:59) \n[GCC Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "1063bb7b3742cd20b598b2a16b6d003634f66b6aa8442a749c3a0dde0987aabf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
